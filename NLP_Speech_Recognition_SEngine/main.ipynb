{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:\\Users\\CS\\Documents\\Caltech AIML\\NLP_Speech_Recognition_SEngine\\TwitterHate.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  label                                              tweet\n",
      "0   1      0   @user when a father is dysfunctional and is s...\n",
      "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
      "2   3      0                                bihday your majesty\n",
      "3   4      0  #model   i love u take with u all the time in ...\n",
      "4   5      0             factsguide: society now    #motivation\n"
     ]
    }
   ],
   "source": [
    "twitter_df = pd.read_csv(file_path)\n",
    "print(twitter_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run', \"@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\", '  bihday your majesty', '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ', ' factsguide: society now    #motivation']\n"
     ]
    }
   ],
   "source": [
    "tweet_list = twitter_df['tweet'].tolist()\n",
    "\n",
    "print(tweet_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'label', 'tweet'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(twitter_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run', \"@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\", '  bihday your majesty', '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ', ' factsguide: society now    #motivation']\n"
     ]
    }
   ],
   "source": [
    "# normalize the casing\n",
    "tweet_list = [tweet.lower() for tweet in tweet_list]\n",
    "\n",
    "print(tweet_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['  when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run', \"  thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\", '  bihday your majesty', '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ', ' factsguide: society now    #motivation']\n"
     ]
    }
   ],
   "source": [
    "# Using regular expressions, remove user handles. These begin with '@’.\n",
    "\n",
    "tweet_list = [re.sub(r'@[^\\s]+', '', tweet) for tweet in tweet_list]\n",
    "\n",
    "print(tweet_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['  when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run', \"  thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\", '  bihday your majesty', '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ', ' factsguide: society now    #motivation']\n"
     ]
    }
   ],
   "source": [
    "# Using regular expressions, remove URLs\n",
    "\n",
    "tweet_list = [re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet) for tweet in tweet_list]\n",
    "\n",
    "print(tweet_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['when', 'a', 'father', 'is', 'dysfunctional', 'and', 'is', 'so', 'selfish', 'he', 'drags', 'his', 'kids', 'into', 'his', 'dysfunction', '.', '#run'], ['thanks', 'for', '#lyft', 'credit', 'i', \"can't\", 'use', 'cause', 'they', \"don't\", 'offer', 'wheelchair', 'vans', 'in', 'pdx', '.', '#disapointed', '#getthanked'], ['bihday', 'your', 'majesty'], ['#model', 'i', 'love', 'u', 'take', 'with', 'u', 'all', 'the', 'time', 'in', 'urð', '\\x9f', '\\x93', '±', '!', '!', '!', 'ð', '\\x9f', '\\x98', '\\x99', 'ð', '\\x9f', '\\x98', '\\x8e', 'ð', '\\x9f', '\\x91', '\\x84', 'ð', '\\x9f', '\\x91', 'ð', '\\x9f', '\\x92', '¦', 'ð', '\\x9f', '\\x92', '¦', 'ð', '\\x9f', '\\x92', '¦'], ['factsguide', ':', 'society', 'now', '#motivation']]\n"
     ]
    }
   ],
   "source": [
    "# Using TweetTokenizer from NLTK, tokenize the tweets into individual terms\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "tweets_tokenized = [tokenizer.tokenize(tweet) for tweet in tweet_list]\n",
    "\n",
    "print(tweets_tokenized[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['father', 'dysfunctional', 'selfish', 'drags', 'kids', 'dysfunction', '.', '#run'], ['thanks', '#lyft', 'credit', \"can't\", 'use', 'cause', 'offer', 'wheelchair', 'vans', 'pdx', '.', '#disapointed', '#getthanked'], ['bihday', 'majesty'], ['#model', 'love', 'u', 'take', 'u', 'time', 'urð', '\\x9f', '\\x93', '±', '!', '!', '!', 'ð', '\\x9f', '\\x98', '\\x99', 'ð', '\\x9f', '\\x98', '\\x8e', 'ð', '\\x9f', '\\x91', '\\x84', 'ð', '\\x9f', '\\x91', 'ð', '\\x9f', '\\x92', '¦', 'ð', '\\x9f', '\\x92', '¦', 'ð', '\\x9f', '\\x92', '¦'], ['factsguide', ':', 'society', '#motivation']]\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "tweets_tokenized = [[word for word in tweet if word not in stop_words] for tweet in tweets_tokenized]\n",
    "\n",
    "print(tweets_tokenized[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['father', 'dysfunctional', 'selfish', 'drags', 'kids', 'dysfunction', '.', '#run'], ['thanks', '#lyft', 'credit', \"can't\", 'use', 'cause', 'offer', 'wheelchair', 'vans', 'pdx', '.', '#disapointed', '#getthanked'], ['bihday', 'majesty'], ['#model', 'love', 'u', 'take', 'u', 'time', 'urð', '\\x9f', '\\x93', '±', '!', '!', '!', 'ð', '\\x9f', '\\x98', '\\x99', 'ð', '\\x9f', '\\x98', '\\x8e', 'ð', '\\x9f', '\\x91', '\\x84', 'ð', '\\x9f', '\\x91', 'ð', '\\x9f', '\\x92', '¦', 'ð', '\\x9f', '\\x92', '¦', 'ð', '\\x9f', '\\x92', '¦'], ['factsguide', ':', 'society', '#motivation']]\n"
     ]
    }
   ],
   "source": [
    "# Remove redundant terms like ‘amp’, ‘rt’,\"#\" etc.\n",
    "\n",
    "tweets_tokenized = [[word for word in tweet if word not in ['amp', 'rt', \"#\"]] for tweet in tweets_tokenized]\n",
    "\n",
    "print(tweets_tokenized[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['father', 'dysfunctional', 'selfish', 'drags', 'kids', 'dysfunction', '#run'], ['thanks', '#lyft', 'credit', \"can't\", 'use', 'cause', 'offer', 'wheelchair', 'vans', 'pdx', '#disapointed', '#getthanked'], ['bihday', 'majesty'], ['#model', 'love', 'take', 'time', 'urð'], ['factsguide', 'society', '#motivation']]\n"
     ]
    }
   ],
   "source": [
    "# Extra cleanup by removing terms with a length of 1\n",
    "\n",
    "tweets_tokenized = [[word for word in tweet if len(word) > 1] for tweet in tweets_tokenized]\n",
    "\n",
    "print(tweets_tokenized[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('...', 2810), ('day', 2022), ('happy', 1568), ('#love', 1542), ('love', 1206), ('time', 1088), (\"i'm\", 1017), ('like', 973), ('today', 941), ('new', 924)]\n"
     ]
    }
   ],
   "source": [
    "# Get all the tokenized terms into 1 large list\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Flatten the list of lists into a single list of terms\n",
    "\n",
    "all_terms = [term for tweet in tweets_tokenized for term in tweet]\n",
    "\n",
    "term_frequencies = Counter(all_terms)\n",
    "\n",
    "# Get the 10 most common terms\n",
    "top_10_terms = term_frequencies.most_common(10)\n",
    "\n",
    "print(top_10_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data formatting for predictive modeling\n",
    "# Join the tokens back to form string ( vectorizers)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tweets_joined = [' '.join(tweet) for tweet in tweets_tokenized]\n",
    "\n",
    "Y = twitter_df['label']\n",
    "X = tweets_joined\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We’ll use TF-IDF values for the terms as a feature to get into a vector space model\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Instantiate TF-IDF Vectorizer with a maximum of 5000 terms in the vocabulary\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the vectorizer on the train set\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test set\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9563142868317103\n",
      "Test Accuracy: 0.9505709369623025\n"
     ]
    }
   ],
   "source": [
    "# Model building: Ordinary Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming X_train_tfidf, Y_train, X_test_tfidf, and Y_test are already defined\n",
    "\n",
    "# Instantiate Logistic Regression with default parameters\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Fit the model to the train data\n",
    "log_reg.fit(X_train_tfidf, Y_train)\n",
    "\n",
    "# Make predictions for the train and the test set\n",
    "train_predictions = log_reg.predict(X_train_tfidf)\n",
    "test_predictions = log_reg.predict(X_test_tfidf)\n",
    "\n",
    "# You can also evaluate the model using metrics like accuracy\n",
    "train_accuracy = accuracy_score(Y_train, train_predictions)\n",
    "test_accuracy = accuracy_score(Y_test, test_predictions)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Accuracy (95.63%) and Test Accuracy (95.06%) are both high: This suggests that the model is performing well in correctly classifying the tweets. It has learned the patterns in the training data effectively and is also generalizing well to new, unseen data (test set).\n",
    "\n",
    "Similarity in Train and Test Accuracies: The close values indicate that there is no significant overfitting. Overfitting would be suggested if the train accuracy was significantly higher than the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9563142868317103\n",
      "Train Recall: 0.39529675251959684\n",
      "Train F1 Score: 0.5583234480031632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "# Assuming log_reg is your trained Logistic Regression model\n",
    "# and X_train_tfidf and Y_train are your training features and labels\n",
    "\n",
    "# Predictions on the train set\n",
    "train_predictions = log_reg.predict(X_train_tfidf)\n",
    "\n",
    "# Accuracy on the train set\n",
    "train_accuracy = accuracy_score(Y_train, train_predictions)\n",
    "\n",
    "# Recall on the train set\n",
    "train_recall = recall_score(Y_train, train_predictions)\n",
    "\n",
    "# F1 score on the train set\n",
    "train_f1_score = f1_score(Y_train, train_predictions)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Train Recall: {train_recall}\")\n",
    "print(f\"Train F1 Score: {train_f1_score}\")\n",
    "\n",
    "# For the recall: \n",
    "# - 'High' generally means close to 1.0\n",
    "# - 'Decent' might be around 0.5 to 0.7\n",
    "# - 'Low' would be closer to 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy: High (95.63%) - Generally good classification.\n",
    "#### Recall: Low (39.53%) - Misses many true positives.\n",
    "#### F1 Score: Moderate (55.83%) - Needs improvement in identifying positive cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Asjust class imbalance\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Adjust class_weight to 'balanced' to handle class imbalance\n",
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# Fit the model to your training data\n",
    "log_reg.fit(X_train_tfidf, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Train Accuracy: 0.9468497008095741\n",
      "Balanced Train Recall: 0.9680851063829787\n",
      "Balanced Train F1 Score: 0.7178741955574008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "# Adjusting the model for class imbalance\n",
    "log_reg_balanced = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# Training the model on the train set\n",
    "log_reg_balanced.fit(X_train_tfidf, Y_train)\n",
    "\n",
    "# Making predictions on the train set\n",
    "train_predictions_balanced = log_reg_balanced.predict(X_train_tfidf)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy_balanced = accuracy_score(Y_train, train_predictions_balanced)\n",
    "recall_balanced = recall_score(Y_train, train_predictions_balanced)\n",
    "f1_score_balanced = f1_score(Y_train, train_predictions_balanced)\n",
    "\n",
    "print(f\"Balanced Train Accuracy: {accuracy_balanced}\")\n",
    "print(f\"Balanced Train Recall: {recall_balanced}\")\n",
    "print(f\"Balanced Train F1 Score: {f1_score_balanced}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the new results with the adjusted class weights to the old results:\n",
    "\n",
    "- **Balanced Accuracy (94.68%) vs. Old Accuracy (95.63%):**\n",
    "  - *Slight decrease* in overall accuracy.\n",
    "  - Still *high*, indicating good general classification ability.\n",
    "\n",
    "- **Balanced Recall (96.81%) vs. Old Recall (39.53%):**\n",
    "  - *Significant increase* in recall.\n",
    "  - Indicates a *substantial improvement* in identifying true positive cases (e.g., better at detecting hate speech).\n",
    "\n",
    "- **Balanced F1 Score (71.79%) vs. Old F1 Score (55.83%):**\n",
    "  - *Notable improvement* in F1 score.\n",
    "  - Suggests a *better balance* between precision and recall, especially in correctly identifying positive cases.\n",
    "\n",
    "**Insights:**\n",
    "- Adjusting for class imbalance leads to a more *sensitive model*, especially in terms of identifying the minority class.\n",
    "- There's a *trade-off* between recall and precision, as seen in the increased recall and slightly decreased accuracy.\n",
    "- The improved F1 score indicates a more *balanced and effective model* for this specific task (e.g., hate speech detection).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization and Hyperparameter tuning:\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Define the parameter grid to search for 'C' and 'penalty' parameters\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Instantiate Logistic Regression with balanced class weight\n",
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# Use StratifiedKFold for handling class imbalance in cross-validation\n",
    "stratified_kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=stratified_kfold, scoring='f1')\n",
    "\n",
    "# Fit GridSearchCV to the training data (use X_train_tfidf and Y_train)\n",
    "grid_search.fit(X_train_tfidf, Y_train)\n",
    "\n",
    "# After fitting, you can get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\CS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\CS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\CS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\CS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\CS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\CS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "24 fits failed out of a total of 48.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\CS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\CS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\CS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\CS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.67861478        nan 0.71165142        nan 0.7737934\n",
      "        nan 0.78275825        nan 0.73012535        nan 0.69204889]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Define the parameter grid to search for 'C' and 'penalty' parameters\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Instantiate Logistic Regression with balanced class weight\n",
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# Use StratifiedKFold with 4 folds for handling class imbalance in cross-validation\n",
    "stratified_kfold = StratifiedKFold(n_splits=4)\n",
    "\n",
    "# Set up GridSearchCV with 'recall' as the metric for scoring\n",
    "grid_search_recall = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=stratified_kfold, scoring='recall')\n",
    "\n",
    "# Fit GridSearchCV to the training data (use X_train_tfidf and Y_train)\n",
    "grid_search_recall.fit(X_train_tfidf, Y_train)\n",
    "\n",
    "# After fitting, you can get the best parameters and best recall score\n",
    "best_params_recall = grid_search_recall.best_params_\n",
    "best_recall_score = grid_search_recall.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'penalty': 'l2'}\n",
      "Test Recall: 0.8004385964912281\n",
      "Test F1 Score: 0.5978705978705979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, f1_score\n",
    "\n",
    "# Assuming grid_search_recall has already been fitted to the training data\n",
    "\n",
    "# Retrieve the best parameters\n",
    "best_params = grid_search_recall.best_params_\n",
    "\n",
    "# Use the best estimator from the grid search\n",
    "best_estimator = grid_search_recall.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = best_estimator.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate the recall on the test set\n",
    "test_recall = recall_score(Y_test, test_predictions)\n",
    "\n",
    "# Calculate the F1 score on the test set\n",
    "test_f1_score = f1_score(Y_test, test_predictions)\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Test F1 Score: {test_f1_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
